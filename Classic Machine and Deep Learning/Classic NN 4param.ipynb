{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d440735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a0f7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(network_history):\n",
    "    plt.figure()\n",
    "    plt.plot(network_history.history['accuracy'])\n",
    "    plt.plot(network_history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Validation'], loc='upper right')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Validation'], loc='lower left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def metrics_best(path, X_val, Y_true):\n",
    "    best_model = load_model(path)\n",
    "    Y_pred = best_model.predict(X_val)\n",
    "    print(confusion_matrix(Y_true, np.where(Y_pred>0.5,1,0)))\n",
    "    print(classification_report(Y_true, np.where(Y_pred>0.5,1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "864d31aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (100,)\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = np.loadtxt(\"iris.txt\")\n",
    "X, Y = iris_dataset[:, 0: 4], iris_dataset[:, -1]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1526a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b331b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, encoded_Y, train_size=0.74, random_state=42, stratify=encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66e9e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f66cbaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=4, activation='sigmoid',use_bias=False))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbad6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"Models\\\\weights.best.4param.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=10, verbose=0, mode='min')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43cda9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B67216D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B67216D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B67216D678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 1.2446 - accuracy: 0.1154WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B6721AA1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B6721AA1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B6721AA1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 1.2899 - accuracy: 0.1117 - val_loss: 1.4138 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.15385, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3100 - accuracy: 0.1310 - val_loss: 1.4069 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.15385\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2932 - accuracy: 0.1117 - val_loss: 1.4001 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.15385\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3042 - accuracy: 0.1117 - val_loss: 1.3933 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.15385\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2675 - accuracy: 0.1021 - val_loss: 1.3865 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.15385\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2664 - accuracy: 0.1214 - val_loss: 1.3798 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.15385\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2482 - accuracy: 0.1454 - val_loss: 1.3731 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.15385\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2366 - accuracy: 0.1310 - val_loss: 1.3664 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.15385\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2215 - accuracy: 0.1166 - val_loss: 1.3598 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.15385\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2290 - accuracy: 0.1069 - val_loss: 1.3532 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.15385\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.2468 - accuracy: 0.1185 - val_loss: 1.3466 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.15385\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3142 - accuracy: 0.15 - 0s 18ms/step - loss: 1.2488 - accuracy: 0.1445 - val_loss: 1.3400 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.15385\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.2187 - accuracy: 0.1205 - val_loss: 1.3335 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.15385\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.2319 - accuracy: 0.1253 - val_loss: 1.3269 - val_accuracy: 0.1538\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.15385\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2152 - accuracy: 0.1156 - val_loss: 1.3205 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.15385 to 0.19231, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.2367 - accuracy: 0.1397 - val_loss: 1.3140 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.19231\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1770 - accuracy: 0.1637 - val_loss: 1.3076 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.19231\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2641 - accuracy: 0.1060 - val_loss: 1.3012 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.19231\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1501 - accuracy: 0.19 - 0s 21ms/step - loss: 1.1652 - accuracy: 0.1541 - val_loss: 1.2949 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.19231\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1935 - accuracy: 0.1445 - val_loss: 1.2886 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.19231\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 1.1802 - accuracy: 0.1301 - val_loss: 1.2823 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.19231\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1672 - accuracy: 0.1253 - val_loss: 1.2760 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.19231\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1236 - accuracy: 0.1589 - val_loss: 1.2698 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.19231\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1445 - accuracy: 0.1512 - val_loss: 1.2636 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.19231\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1766 - accuracy: 0.1464 - val_loss: 1.2575 - val_accuracy: 0.1923\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.19231\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1673 - accuracy: 0.1388 - val_loss: 1.2513 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.19231 to 0.23077, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1040 - accuracy: 0.1869 - val_loss: 1.2452 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.23077\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1007 - accuracy: 0.19 - 0s 16ms/step - loss: 1.1108 - accuracy: 0.1772 - val_loss: 1.2391 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.23077\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1269 - accuracy: 0.1744 - val_loss: 1.2331 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.23077\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.1673 - accuracy: 0.1503 - val_loss: 1.2270 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.23077\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1494 - accuracy: 0.1359 - val_loss: 1.2211 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.23077\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0894 - accuracy: 0.1648 - val_loss: 1.2151 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.23077\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0931 - accuracy: 0.2100 - val_loss: 1.2092 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.23077\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1001 - accuracy: 0.2052 - val_loss: 1.2034 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.23077\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 1.0999 - accuracy: 0.2023 - val_loss: 1.1975 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.23077\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.1038 - accuracy: 0.1975 - val_loss: 1.1917 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.23077\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.0612 - accuracy: 0.1975 - val_loss: 1.1859 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.23077\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 1.1063 - accuracy: 0.2071 - val_loss: 1.1801 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.23077\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 104ms/step - loss: 1.0961 - accuracy: 0.1639 - val_loss: 1.1743 - val_accuracy: 0.2308\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.23077\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 1.0543 - accuracy: 0.1879 - val_loss: 1.1686 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.23077 to 0.26923, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.0683 - accuracy: 0.2139 - val_loss: 1.1629 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.26923\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 1.0340 - accuracy: 0.2447 - val_loss: 1.1573 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.26923\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.0830 - accuracy: 0.2130 - val_loss: 1.1517 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.26923\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 1.0116 - accuracy: 0.2899 - val_loss: 1.1461 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.26923\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 1.0097 - accuracy: 0.2659 - val_loss: 1.1405 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.26923\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 1.0754 - accuracy: 0.1841 - val_loss: 1.1350 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.26923\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.0205 - accuracy: 0.2322 - val_loss: 1.1295 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.26923\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.0164 - accuracy: 0.2707 - val_loss: 1.1240 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.26923\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.0044 - accuracy: 0.2370 - val_loss: 1.1186 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.26923\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9730 - accuracy: 0.2514 - val_loss: 1.1132 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.26923\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.9868 - accuracy: 0.2562 - val_loss: 1.1078 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.26923\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 1.0084 - accuracy: 0.2178 - val_loss: 1.1024 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.26923\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.0379 - accuracy: 0.2390 - val_loss: 1.0971 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.26923\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9536 - accuracy: 0.2534 - val_loss: 1.0918 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.26923\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.9553 - accuracy: 0.2966 - val_loss: 1.0866 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.26923\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 1.0261 - accuracy: 0.2601 - val_loss: 1.0813 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.26923\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.9979 - accuracy: 0.2669 - val_loss: 1.0761 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.26923\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.9649 - accuracy: 0.2669 - val_loss: 1.0709 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.26923\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.9561 - accuracy: 0.2957 - val_loss: 1.0657 - val_accuracy: 0.2692\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.26923\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9310 - accuracy: 0.2765 - val_loss: 1.0606 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00060: val_accuracy improved from 0.26923 to 0.30769, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9257 - accuracy: 0.3246 - val_loss: 1.0555 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.30769\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.8836 - accuracy: 0.3073 - val_loss: 1.0504 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.30769\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9496 - accuracy: 0.2688 - val_loss: 1.0454 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.30769\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9467 - accuracy: 0.3121 - val_loss: 1.0403 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.30769\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9203 - accuracy: 0.3545 - val_loss: 1.0353 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.30769\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8939 - accuracy: 0.3680 - val_loss: 1.0304 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.30769\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9335 - accuracy: 0.3584 - val_loss: 1.0254 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.30769\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.9166 - accuracy: 0.3199 - val_loss: 1.0205 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.30769\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8871 - accuracy: 0.3968 - val_loss: 1.0156 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.30769\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.8893 - accuracy: 0.3439 - val_loss: 1.0108 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.30769\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.9100 - accuracy: 0.3247 - val_loss: 1.0060 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.30769\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.8882 - accuracy: 0.3343 - val_loss: 1.0012 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.30769\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9119 - accuracy: 0.3459 - val_loss: 0.9964 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.30769\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8929 - accuracy: 0.3507 - val_loss: 0.9917 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.30769\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.8917 - accuracy: 0.3699 - val_loss: 0.9869 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.30769\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8446 - accuracy: 0.3844 - val_loss: 0.9823 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.30769\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8522 - accuracy: 0.3603 - val_loss: 0.9776 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.30769\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.8671 - accuracy: 0.3555 - val_loss: 0.9730 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.30769\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8391 - accuracy: 0.4498 - val_loss: 0.9684 - val_accuracy: 0.3077\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.30769\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.8435 - accuracy: 0.4402 - val_loss: 0.9638 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00080: val_accuracy improved from 0.30769 to 0.34615, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8770 - accuracy: 0.3873 - val_loss: 0.9592 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.34615\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.8649 - accuracy: 0.4037 - val_loss: 0.9546 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.34615\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.8467 - accuracy: 0.4461 - val_loss: 0.9501 - val_accuracy: 0.3462\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.34615\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.8428 - accuracy: 0.4413 - val_loss: 0.9457 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00084: val_accuracy improved from 0.34615 to 0.38462, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.8662 - accuracy: 0.4220 - val_loss: 0.9412 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.38462\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.8404 - accuracy: 0.4365 - val_loss: 0.9368 - val_accuracy: 0.3846\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.38462\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.8348 - accuracy: 0.4605 - val_loss: 0.9324 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00087: val_accuracy improved from 0.38462 to 0.42308, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7909 - accuracy: 0.4990 - val_loss: 0.9280 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.42308\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7852 - accuracy: 0.4797 - val_loss: 0.9237 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.42308\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7676 - accuracy: 0.4990 - val_loss: 0.9194 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.42308\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7819 - accuracy: 0.4365 - val_loss: 0.9150 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.42308\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8029 - accuracy: 0.4365 - val_loss: 0.9107 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.42308\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7865 - accuracy: 0.4413 - val_loss: 0.9065 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.42308\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7741 - accuracy: 0.4845 - val_loss: 0.9022 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.42308\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7942 - accuracy: 0.4845 - val_loss: 0.8980 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.42308\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7644 - accuracy: 0.4749 - val_loss: 0.8938 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.42308\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7716 - accuracy: 0.4557 - val_loss: 0.8896 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.42308\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7639 - accuracy: 0.4557 - val_loss: 0.8855 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.42308\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7911 - accuracy: 0.4548 - val_loss: 0.8814 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.42308\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7438 - accuracy: 0.5077 - val_loss: 0.8773 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.42308\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7917 - accuracy: 0.4500 - val_loss: 0.8732 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.42308\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7710 - accuracy: 0.4788 - val_loss: 0.8692 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.42308\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7925 - accuracy: 0.4356 - val_loss: 0.8651 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.42308\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7445 - accuracy: 0.4692 - val_loss: 0.8612 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.42308\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7290 - accuracy: 0.4836 - val_loss: 0.8572 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00105: val_accuracy improved from 0.42308 to 0.50000, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7571 - accuracy: 0.4808 - val_loss: 0.8532 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.50000\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7424 - accuracy: 0.4808 - val_loss: 0.8493 - val_accuracy: 0.5385\n",
      "\n",
      "Epoch 00107: val_accuracy improved from 0.50000 to 0.53846, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7084 - accuracy: 0.5240 - val_loss: 0.8454 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00108: val_accuracy improved from 0.53846 to 0.57692, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7342 - accuracy: 0.4952 - val_loss: 0.8415 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.57692\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7314 - accuracy: 0.4712 - val_loss: 0.8376 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.57692\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7151 - accuracy: 0.5048 - val_loss: 0.8338 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.57692\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6939 - accuracy: 0.5240 - val_loss: 0.8300 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.57692\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7082 - accuracy: 0.4856 - val_loss: 0.8262 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.57692\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6776 - accuracy: 0.5385 - val_loss: 0.8224 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.57692\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7032 - accuracy: 0.4808 - val_loss: 0.8187 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.57692\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.6946 - accuracy: 0.5192 - val_loss: 0.8149 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.57692\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.7050 - accuracy: 0.5000 - val_loss: 0.8112 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.57692\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.7010 - accuracy: 0.4971 - val_loss: 0.8075 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.57692\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7025 - accuracy: 0.5511 - val_loss: 0.8038 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.57692\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6968 - accuracy: 0.5463 - val_loss: 0.8002 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.57692\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6811 - accuracy: 0.5530 - val_loss: 0.7966 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.57692\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7063 - accuracy: 0.5097 - val_loss: 0.7930 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.57692\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6999 - accuracy: 0.5578 - val_loss: 0.7894 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.57692\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6710 - accuracy: 0.5915 - val_loss: 0.7858 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.57692\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6571 - accuracy: 0.5867 - val_loss: 0.7823 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.57692\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7107 - accuracy: 0.5761 - val_loss: 0.7787 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.57692\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6438 - accuracy: 0.6338 - val_loss: 0.7752 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.57692\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6768 - accuracy: 0.5810 - val_loss: 0.7718 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.57692\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6669 - accuracy: 0.5877 - val_loss: 0.7683 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.57692\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.6323 - accuracy: 0.6262 - val_loss: 0.7649 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.57692\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6591 - accuracy: 0.6041 - val_loss: 0.7615 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.57692\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6497 - accuracy: 0.5897 - val_loss: 0.7581 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.57692\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6566 - accuracy: 0.6301 - val_loss: 0.7547 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.57692\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.6200 - accuracy: 0.6397 - val_loss: 0.7513 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.57692\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.6201 - accuracy: 0.6445 - val_loss: 0.7480 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.57692\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6275 - accuracy: 0.6349 - val_loss: 0.7447 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.57692\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6367 - accuracy: 0.6080 - val_loss: 0.7414 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.57692\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6163 - accuracy: 0.6628 - val_loss: 0.7381 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.57692\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6406 - accuracy: 0.6436 - val_loss: 0.7348 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.57692\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6607 - accuracy: 0.5907 - val_loss: 0.7316 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.57692\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6189 - accuracy: 0.6340 - val_loss: 0.7283 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.57692\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6273 - accuracy: 0.6388 - val_loss: 0.7251 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.57692\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6271 - accuracy: 0.6340 - val_loss: 0.7219 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.57692\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5991 - accuracy: 0.6888 - val_loss: 0.7188 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.57692\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6043 - accuracy: 0.6792 - val_loss: 0.7156 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.57692\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5783 - accuracy: 0.6936 - val_loss: 0.7125 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.57692\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5910 - accuracy: 0.7100 - val_loss: 0.7094 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.57692\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5747 - accuracy: 0.7196 - val_loss: 0.7063 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.57692\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5939 - accuracy: 0.6859 - val_loss: 0.7032 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.57692\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6347 - accuracy: 0.6398 - val_loss: 0.7001 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.57692\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5499 - accuracy: 0.7408 - val_loss: 0.6970 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.57692\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5919 - accuracy: 0.7071 - val_loss: 0.6940 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.57692\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5625 - accuracy: 0.7215 - val_loss: 0.6910 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.57692\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5745 - accuracy: 0.6975 - val_loss: 0.6880 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.57692\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5256 - accuracy: 0.7648 - val_loss: 0.6851 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.57692\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5587 - accuracy: 0.7312 - val_loss: 0.6821 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.57692\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5684 - accuracy: 0.7167 - val_loss: 0.6792 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.57692\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5815 - accuracy: 0.6735 - val_loss: 0.6762 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.57692\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5816 - accuracy: 0.6975 - val_loss: 0.6733 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.57692\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5642 - accuracy: 0.7071 - val_loss: 0.6704 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.57692\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.5696 - accuracy: 0.6879 - val_loss: 0.6675 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.57692\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5566 - accuracy: 0.7206 - val_loss: 0.6647 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00162: val_accuracy improved from 0.57692 to 0.61538, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5445 - accuracy: 0.7514 - val_loss: 0.6619 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.61538\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5461 - accuracy: 0.7370 - val_loss: 0.6590 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.61538\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5490 - accuracy: 0.7418 - val_loss: 0.6562 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.61538\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5354 - accuracy: 0.7514 - val_loss: 0.6535 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.61538\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5176 - accuracy: 0.7803 - val_loss: 0.6507 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.61538\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5235 - accuracy: 0.7514 - val_loss: 0.6479 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.61538\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4952 - accuracy: 0.7774 - val_loss: 0.6452 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.61538\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4783 - accuracy: 0.7966 - val_loss: 0.6425 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.61538\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5267 - accuracy: 0.7486 - val_loss: 0.6397 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.61538\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5325 - accuracy: 0.7438 - val_loss: 0.6370 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.61538\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5206 - accuracy: 0.7534 - val_loss: 0.6343 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.61538\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5107 - accuracy: 0.7630 - val_loss: 0.6317 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.61538\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5135 - accuracy: 0.7630 - val_loss: 0.6290 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.61538\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5200 - accuracy: 0.7678 - val_loss: 0.6263 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.61538\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.5170 - accuracy: 0.7601 - val_loss: 0.6237 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.61538\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5117 - accuracy: 0.7553 - val_loss: 0.6211 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.61538\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5136 - accuracy: 0.7698 - val_loss: 0.6185 - val_accuracy: 0.6154\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.61538\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5119 - accuracy: 0.7457 - val_loss: 0.6160 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00180: val_accuracy improved from 0.61538 to 0.65385, saving model to Models\\weights.best.4param.hdf5\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5417 - accuracy: 0.7217 - val_loss: 0.6134 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.65385\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5277 - accuracy: 0.7361 - val_loss: 0.6108 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.65385\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4910 - accuracy: 0.7746 - val_loss: 0.6083 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.65385\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4833 - accuracy: 0.7794 - val_loss: 0.6058 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.65385\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4820 - accuracy: 0.7746 - val_loss: 0.6033 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.65385\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4894 - accuracy: 0.7794 - val_loss: 0.6008 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.65385\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4888 - accuracy: 0.7457 - val_loss: 0.5984 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.65385\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4974 - accuracy: 0.7457 - val_loss: 0.5959 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.65385\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4939 - accuracy: 0.7505 - val_loss: 0.5934 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.65385\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4747 - accuracy: 0.7746 - val_loss: 0.5910 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.65385\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4555 - accuracy: 0.7986 - val_loss: 0.5886 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.65385\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4866 - accuracy: 0.7505 - val_loss: 0.5862 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.65385\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4517 - accuracy: 0.8034 - val_loss: 0.5838 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.65385\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5121 - accuracy: 0.7217 - val_loss: 0.5814 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.65385\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.4565 - accuracy: 0.7957 - val_loss: 0.5791 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.65385\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4718 - accuracy: 0.8025 - val_loss: 0.5767 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.65385\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4361 - accuracy: 0.8506 - val_loss: 0.5744 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.65385\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4603 - accuracy: 0.8025 - val_loss: 0.5721 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.65385\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4857 - accuracy: 0.7496 - val_loss: 0.5697 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.65385\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4394 - accuracy: 0.8073 - val_loss: 0.5674 - val_accuracy: 0.6538\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.65385\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "network_history = model.fit(X_train, Y_train, batch_size=len(X_val), epochs=n_epochs, callbacks=callbacks_list, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f61c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12fc3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B673255C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B673255C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B673255C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B673255C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B673255C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 4]\n",
      " [5 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.69      0.67        13\n",
      "           1       0.67      0.62      0.64        13\n",
      "\n",
      "    accuracy                           0.65        26\n",
      "   macro avg       0.65      0.65      0.65        26\n",
      "weighted avg       0.65      0.65      0.65        26\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path=\"Models\\\\weights.best.4param.hdf5\"\n",
    "#Y_val_no_encoded = np.where(Y_val<0,0,Y_val_no_encoded)\n",
    "metrics_best(path,X_val,Y_val)\n",
    "plot(network_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
